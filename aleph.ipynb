{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALEPH\n",
    "a PoC for conversational research environment with ADA and GPT3.5\n",
    "\n",
    "Sources:\n",
    "- How_to_format_inputs_to_ChatGPT_models: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_format_inputs_to_ChatGPT_models.ipynb\n",
    "- Question_answering_using_embeddings: https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai, pickle, tiktoken, ast\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re, sqlite3\n",
    "\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "import pprint\n",
    "\n",
    "import utils as utl\n",
    "import params as prm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your own key\n",
    "# read secret key from secret file \n",
    "with open('secret.txt', 'r') as f:\n",
    "    openai.api_key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today date is:  2023-03-16\n"
     ]
    }
   ],
   "source": [
    "# Returns the current local date\n",
    "today = date.today()\n",
    "print(\"Today date is: \", today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name = 'good_incontext_examples_for_gpt3'\n",
    "session_date = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to user's database\n",
    "conn = utl.create_connection(prm.DB_PTH) # Create connection to the database\n",
    "\n",
    "utl.create_table(conn, prm.SESSION_TABLE_SQL) # Create table if it does not exist\n",
    "# Create interaction table for the session\n",
    "utl.create_table(conn, f\"CREATE TABLE IF NOT EXISTS interaction_{session_name} (session_name, interaction_type, text, embedding, num_tokens_oai, time_signature)\")\n",
    "\n",
    "\n",
    "tables = utl.parse_tables(conn) # Grab tables to check if the table was created\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session: \"good_incontext_examples_for_gpt3\" inserted into the database\n"
     ]
    }
   ],
   "source": [
    "# DB INTERACTION\n",
    "# Write session data to the database\n",
    "conn = utl.create_connection(prm.DB_PTH) # Create connection to the database\n",
    "utl.insert_session(conn, session_name, session_date) # Insert session data  \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare document for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic for chapter capture\n",
    "# digit_word_rgx = r'^\\d+(\\.\\d+)*\\s+[A-Z].*$|Abstract'\n",
    "digit_word_rgx = r'^\\d+(\\.\\d+)*\\s[a-zA-Z]+.*$|Abstract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load context document and grab chapter names\n",
    "doc_name = 'What Makes Good InContext Examples for GPT3.pdf'\n",
    "\n",
    "pdf_text = extract_text(prm.IN_PTH / doc_name)\n",
    "\n",
    "# TODO: user should decide which split logic to use: random split (text be be cut into equal parts containing more-less the same number of tokens) or split by chapters (chapter inference is not always correct as pdfs are not always formated nicely). \n",
    "# TODO: Implement interface for split choice + equal chunking function\n",
    "chapters = utl.grab_chapters(pdf_text, matching_logic=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abstract',\n",
       " '3 keeps generating tokens until there is a special char-',\n",
       " '2 Method',\n",
       " '2.1 GPT-3 for In-Context Learning',\n",
       " '2.2 The Impact of In-Context Examples',\n",
       " '2.3 kNN-augmented In-Context Example',\n",
       " '3 Experimental Setup',\n",
       " '3.1 Sentence Embeddings for Retrieval',\n",
       " '3 on open-domain QA tasks. The EM score is',\n",
       " '3.2 Baseline Methods',\n",
       " '4 Experimental Results',\n",
       " '4.1 Sentiment Analysis',\n",
       " '2 dataset, the accuracy of kNNsst-2 is 92.46, which',\n",
       " '4.2 Table-to-text Generation',\n",
       " '4.3 Questing Answering',\n",
       " '64 nearest neighbors (10 for TriviaQA) to deter-',\n",
       " '3 to misinterpret the question as asking for a spe-',\n",
       " '64 examples.',\n",
       " '5 Analysis and Ablation Study',\n",
       " '5.1 Number of In-context Examples',\n",
       " '5.2 Size of Training Set for Retrieval',\n",
       " '3 to better answer the questions.',\n",
       " '5.3 Order of In-context Examples',\n",
       " '6 Related Work',\n",
       " '7 Conclusion']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what chapters got captured from the pdf\n",
    "chapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19 chapters in the document\n"
     ]
    }
   ],
   "source": [
    "# TODO: interface for selecting chapters to be used for text fragmentation. \n",
    "chapters = [\n",
    "    'Abstract',\n",
    "    '1 Introduction',\n",
    "    '2 Method',\n",
    "    '2.1 GPT-3 for In-Context Learning',\n",
    "    '2.2 The Impact of In-Context Examples',\n",
    "    '2.3 kNN-augmented In-Context Example',\n",
    "    '3 Experimental Setup',\n",
    "    '3.1 Sentence Embeddings for Retrieval',\n",
    "    '3.2 Baseline Methods',\n",
    "    '4 Experimental Results',\n",
    "    '4.1 Sentiment Analysis',\n",
    "    '4.2 Table-to-text Generation',\n",
    "    '4.3 Questing Answering',\n",
    "    '5 Analysis and Ablation Study',\n",
    "    '5.1 Number of In-context Examples',\n",
    "    '5.2 Size of Training Set for Retrieval',\n",
    "    '5.3 Order of In-context Examples',\n",
    "    '6 Related Work',\n",
    "    '7 Conclusion'\n",
    "]\n",
    "chapters = [x.lower().strip() for x in chapters]\n",
    "print(f\"There are {len(chapters)} chapters in the document\")\n",
    "\n",
    "\n",
    "# Set a specific starting point of the document\n",
    "# start = 'abstract'\n",
    "start = chapters[0]\n",
    "\n",
    "start = start.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make this text pre-processing function\n",
    "# define the text to be parsed\n",
    "text = [] \n",
    "for line in pdf_text.split('\\n'):\n",
    "    # if len(line)<=1: #get rid of junk lines\n",
    "    #     continue\n",
    "    line = line.replace('\\t', ' ')\n",
    "    line = line.strip().lower()\n",
    "    text.append(line)\n",
    "\n",
    "text = ' '.join(text)\n",
    "# replace newline and tab characters with space\n",
    "text = text.replace('\\n', '')\n",
    "text = text.replace('\\t', '')\n",
    "text = re.sub(r'\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: turn it into a function that will get triggered whe user decides to chop the document by chapter names\n",
    "\n",
    "# Fragment the text according to the logic the user defined (currently - by chapters)\n",
    "\n",
    "# join the end strings with | to form chapter end regex pattern\n",
    "end_pattern = \"|\".join(chapters)\n",
    "\n",
    "# match text between chapter and any end string\n",
    "chapters_contents = {}\n",
    "for string in chapters:\n",
    "\n",
    "    pattern = rf\"{string}(.*?)(\" + end_pattern + \"|$)\"\n",
    "    pattern = re.compile(pattern)\n",
    "\n",
    "\n",
    "\n",
    "    # search for the pattern in the text\n",
    "    match = pattern.search(text)\n",
    "\n",
    "    # if there is a match, extract the text between string and any end-string\n",
    "    if match:\n",
    "        # get the first group of the match object, which is the text between given chapter and any end string\n",
    "        result = match.group(1)\n",
    "\n",
    "        # print or save or do whatever you want with the result\n",
    "        chapters_contents[string] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: come up with test that checks if I grabbed all the chapters\n",
    "fetched_chapters = [x for x in chapters_contents.keys()] \n",
    "# compare element wise fetched_chapters with chapters\n",
    "[x for x in chapters if x not in fetched_chapters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' gpt-3 (brown et al., 2020) is a new breakthrough in nlp research. previously, nlp models are pre- trained on large quantities of data and ﬁne-tuned ∗work was done during an internship at microsoft dy- namics 365 ai. trial accuracy 1 94.6 2 95.0 3 95.8 4 93.9 5 86.9 table 1: results of gpt-3 on the task of sentiment analysis on the sst-2 dataset. five different in-context examples are randomly selected from the training set. we observe different contexts induce different accura- cies on the test set. on a speciﬁc task and dataset. what sets gpt-3 apart from other pre-trained language models is its impressive “in-context” few-shot learning ability. provided with a few in-context examples, gpt-3 is able to generalize to unseen cases without fur- ther ﬁne-tuning. this opens up many new tech- nological possibilities that are previously consid- ered unique to human. for example, nlp systems can be developed to expand emails, extract entities from text, generate code based on natural language instructions with a few demonstration examples. despite its powerful and versatile in-context learning ability, gpt-3 has some practical chal- lenges/ambiguities. the original paper (brown et al., 2020) utilizes task-relevant examples that are randomly sampled from the training set to con- struct the context. in practice, we observe that the performance of gpt-3 tends to ﬂuctuate with dif- ferent choices of in-context examples. as shown in table 1, the variance of the empirical results with distinct in-context examples can be signiﬁ- cant. the results are highly sensitive to the exam- ples. our work aims to carefully examine this is- sue to gain a deeper understanding on how to bet- ter select in-context examples to unleash gpt-3’s few-shot capabilities and further improve its per- formance. a brute-force approach would be to perform combinatorial search over the entire dataset. un- fortunately, this strategy is computationally ex- pensive and thus impractical in many cases. to this end, we investigate the inﬂuences of employ- ing different in-context examples on the empiri- cal results. interestingly, we found that the in- context examples that are closer to the test sample in the embedding space consistently give rise to stronger performance (relative to the farther ones). inspired by this observation and the recent success of retrieval-augmented models (hashimoto et al., 2018), we propose to utilize nearest neighbors of a given test sample (among all the training instances available) as the corresponding in-context exam- ples. the retrieved examples, along with the test sample, are provided to gpt-3 for the ﬁnal predic- tion. to verify the effectiveness of the proposed method, we evaluate it on several natural language understanding and generation tasks, including sen- timent analysis, table-to-text generation and open- domain question answering. it is observed that the retrieval-based in-context examples unleash the few-shot capabilities of gpt-3 much more ef- fectively than a random sampling baseline. even with a smaller number of in-context examples, the proposed strategy empowers gpt-3 to achieve stronger performance. moreover, we ﬁnd that the speciﬁc sentence encoders employed for the re- trieval procedure play a critical role. thus, an ex- tensive exploration regarding different pre-trained encoders is conducted, and it is shown that en- coders ﬁne-tuned on natural language matching tasks serve as more effective in-context examples selector on the qa task. detailed analysis and case study further validate the effectiveness of pro- posed methods. in summary, our contributions in this paper are as follows: i) to the best of our knowledge, we take a ﬁrst step towards understanding the sensitivity of gpt- 3’s few-shot capabilities with respect to the selec- tion of in-context examples; ii) to alleviate the sensitivity issue, an ad- ditional retrieval module is introduced to ﬁnd semantically-similar in-context examples of a test instance to construct its corresponding input, which greatly outperforms the baseline based on random sampled examples; iii) ﬁne-tuning the retrieval model on task- related dataset(s) leads to even stronger empirical results with gpt-3; iv) the performance of gpt-3 improves as the number of examples available for retrieval in- creases. figure 1: the ﬁgure above shows how to perform in- context learning with a language model. three in- context examples and the test prompt are concatenated as a single string input for gpt-3, with a special charac- ter ”\\\\n” inserted between two adjacent examples. gpt- 3 keeps generating tokens until there is a special char- acter ”\\\\n”. '"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually inspect some chapters\n",
    "chapters_contents['1 introduction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abstract</th>\n",
       "      <td>gpt-3 (brown et al., 2020) has attracted lots...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 introduction</th>\n",
       "      <td>gpt-3 (brown et al., 2020) is a new breakthro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 method</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1 gpt-3 for in-context learning</th>\n",
       "      <td>the in-context learning scenario of gpt-3 can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2 the impact of in-context examples</th>\n",
       "      <td>given the observation that the empirical resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3 knn-augmented in-context example</th>\n",
       "      <td>selection based on the ﬁndings above, we prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 experimental setup</th>\n",
       "      <td>we apply the knn in-context selection method ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.1 sentence embeddings for retrieval</th>\n",
       "      <td>to retrieve semantically-similar training ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2 baseline methods</th>\n",
       "      <td>random sampling for each test sentence, we ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 experimental results</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.1 sentiment analysis</th>\n",
       "      <td>we ﬁrst evaluate kate on the sentiment anal- ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.2 table-to-text generation</th>\n",
       "      <td>we utilize the totto dataset to evaluate kate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.3 questing answering</th>\n",
       "      <td>we also evaluate kate on the open-domain qa t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 analysis and ablation study</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.1 number of in-context examples</th>\n",
       "      <td>we ﬁrst investigate the impact of the number ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.2 size of training set for retrieval</th>\n",
       "      <td>we further examine how the size of the traini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.3 order of in-context examples</th>\n",
       "      <td>moreover, we explore how the order of in-cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 related work</th>\n",
       "      <td>pre-trained language models nlp systems have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 conclusion</th>\n",
       "      <td>this work presented a ﬁrst step towards inves...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 contents\n",
       "abstract                                 gpt-3 (brown et al., 2020) has attracted lots...\n",
       "1 introduction                           gpt-3 (brown et al., 2020) is a new breakthro...\n",
       "2 method                                                                                 \n",
       "2.1 gpt-3 for in-context learning        the in-context learning scenario of gpt-3 can...\n",
       "2.2 the impact of in-context examples    given the observation that the empirical resu...\n",
       "2.3 knn-augmented in-context example     selection based on the ﬁndings above, we prop...\n",
       "3 experimental setup                     we apply the knn in-context selection method ...\n",
       "3.1 sentence embeddings for retrieval    to retrieve semantically-similar training ins...\n",
       "3.2 baseline methods                     random sampling for each test sentence, we ra...\n",
       "4 experimental results                                                                   \n",
       "4.1 sentiment analysis                   we ﬁrst evaluate kate on the sentiment anal- ...\n",
       "4.2 table-to-text generation             we utilize the totto dataset to evaluate kate...\n",
       "4.3 questing answering                   we also evaluate kate on the open-domain qa t...\n",
       "5 analysis and ablation study                                                            \n",
       "5.1 number of in-context examples        we ﬁrst investigate the impact of the number ...\n",
       "5.2 size of training set for retrieval   we further examine how the size of the traini...\n",
       "5.3 order of in-context examples         moreover, we explore how the order of in-cont...\n",
       "6 related work                           pre-trained language models nlp systems have ...\n",
       "7 conclusion                             this work presented a ﬁrst step towards inves..."
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grab contents into a dataframe\n",
    "chapter_contents_df = pd.DataFrame(chapters_contents, index=['contents'])\n",
    "chapter_contents_df = chapter_contents_df.T\n",
    "chapter_contents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a token count column\n",
    "chapter_contents_df['num_tokens_oai'] = chapter_contents_df['contents'].apply(\n",
    "    lambda x: utl.num_tokens_from_messages([{'message': x}])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For instances with token count > token_thres, split them so they fit model threshold so we could get their embeddings\n",
    "# TODO: make it split actually by tokens, not by characters\n",
    "\n",
    "token_thres = 500\n",
    "\n",
    "chapter_contents_df['split_factor'] = 1\n",
    "chapter_contents_df.loc[chapter_contents_df['num_tokens_oai'] > token_thres, 'split_factor'] = round(chapter_contents_df['num_tokens_oai']/token_thres,0)\n",
    "\n",
    "\n",
    "chapter_contents_df['contents_split'] = chapter_contents_df.apply(\n",
    "    lambda x: utl.split_contents(x), axis=1)\n",
    "\n",
    "\n",
    "chapter_contents_long_df = chapter_contents_df.explode(\n",
    "    column='contents_split'\n",
    ")[['contents_split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents_split</th>\n",
       "      <th>num_tokens_oai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abstract</th>\n",
       "      <td>gpt-3 (brown et al., 2020) has attracted lots...</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 introduction</th>\n",
       "      <td>gpt-3 (brown et al., 2020) is a new breakthro...</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 introduction</th>\n",
       "      <td>he recent success of retrieval-augmented model...</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 method</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1 gpt-3 for in-context learning</th>\n",
       "      <td>the in-context learning scenario of gpt-3 can...</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2 the impact of in-context examples</th>\n",
       "      <td>given the observation that the empirical resu...</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3 knn-augmented in-context example</th>\n",
       "      <td>selection based on the ﬁndings above, we prop...</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3 knn-augmented in-context example</th>\n",
       "      <td>number of in-context examples k (hyperparamete...</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 experimental setup</th>\n",
       "      <td>we apply the knn in-context selection method ...</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.1 sentence embeddings for retrieval</th>\n",
       "      <td>to retrieve semantically-similar training ins...</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.1 sentence embeddings for retrieval</th>\n",
       "      <td>table and a set of highlighted cells, this tas...</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2 baseline methods</th>\n",
       "      <td>random sampling for each test sentence, we ra...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 experimental results</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.1 sentiment analysis</th>\n",
       "      <td>we ﬁrst evaluate kate on the sentiment anal- ...</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.2 table-to-text generation</th>\n",
       "      <td>we utilize the totto dataset to evaluate kate...</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.3 questing answering</th>\n",
       "      <td>we also evaluate kate on the open-domain qa t...</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.3 questing answering</th>\n",
       "      <td>and gpt-3 work together to achieve better per...</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.3 questing answering</th>\n",
       "      <td>lege &lt;table&gt;&lt;cell&gt;3.8 &lt;col header&gt; rpg &lt;cell&gt;2...</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 analysis and ablation study</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.1 number of in-context examples</th>\n",
       "      <td>we ﬁrst investigate the impact of the number ...</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.2 size of training set for retrieval</th>\n",
       "      <td>we further examine how the size of the traini...</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.2 size of training set for retrieval</th>\n",
       "      <td>? bull where did zeus spend most of his time? ...</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.2 size of training set for retrieval</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.3 order of in-context examples</th>\n",
       "      <td>moreover, we explore how the order of in-cont...</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 related work</th>\n",
       "      <td>pre-trained language models nlp systems have ...</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 related work</th>\n",
       "      <td>al., 2018; wu et al., 2019), text summa- riza...</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 related work</th>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 conclusion</th>\n",
       "      <td>this work presented a ﬁrst step towards inves...</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           contents_split  \\\n",
       "abstract                                 gpt-3 (brown et al., 2020) has attracted lots...   \n",
       "1 introduction                           gpt-3 (brown et al., 2020) is a new breakthro...   \n",
       "1 introduction                          he recent success of retrieval-augmented model...   \n",
       "2 method                                                                                    \n",
       "2.1 gpt-3 for in-context learning        the in-context learning scenario of gpt-3 can...   \n",
       "2.2 the impact of in-context examples    given the observation that the empirical resu...   \n",
       "2.3 knn-augmented in-context example     selection based on the ﬁndings above, we prop...   \n",
       "2.3 knn-augmented in-context example    number of in-context examples k (hyperparamete...   \n",
       "3 experimental setup                     we apply the knn in-context selection method ...   \n",
       "3.1 sentence embeddings for retrieval    to retrieve semantically-similar training ins...   \n",
       "3.1 sentence embeddings for retrieval   table and a set of highlighted cells, this tas...   \n",
       "3.2 baseline methods                     random sampling for each test sentence, we ra...   \n",
       "4 experimental results                                                                      \n",
       "4.1 sentiment analysis                   we ﬁrst evaluate kate on the sentiment anal- ...   \n",
       "4.2 table-to-text generation             we utilize the totto dataset to evaluate kate...   \n",
       "4.3 questing answering                   we also evaluate kate on the open-domain qa t...   \n",
       "4.3 questing answering                   and gpt-3 work together to achieve better per...   \n",
       "4.3 questing answering                  lege <table><cell>3.8 <col header> rpg <cell>2...   \n",
       "5 analysis and ablation study                                                               \n",
       "5.1 number of in-context examples        we ﬁrst investigate the impact of the number ...   \n",
       "5.2 size of training set for retrieval   we further examine how the size of the traini...   \n",
       "5.2 size of training set for retrieval  ? bull where did zeus spend most of his time? ...   \n",
       "5.2 size of training set for retrieval                                                      \n",
       "5.3 order of in-context examples         moreover, we explore how the order of in-cont...   \n",
       "6 related work                           pre-trained language models nlp systems have ...   \n",
       "6 related work                           al., 2018; wu et al., 2019), text summa- riza...   \n",
       "6 related work                                                                              \n",
       "7 conclusion                             this work presented a ﬁrst step towards inves...   \n",
       "\n",
       "                                        num_tokens_oai  \n",
       "abstract                                           338  \n",
       "1 introduction                                     549  \n",
       "1 introduction                                     511  \n",
       "2 method                                             7  \n",
       "2.1 gpt-3 for in-context learning                  489  \n",
       "2.2 the impact of in-context examples              377  \n",
       "2.3 knn-augmented in-context example               415  \n",
       "2.3 knn-augmented in-context example               425  \n",
       "3 experimental setup                               246  \n",
       "3.1 sentence embeddings for retrieval              440  \n",
       "3.1 sentence embeddings for retrieval              436  \n",
       "3.2 baseline methods                               416  \n",
       "4 experimental results                               7  \n",
       "4.1 sentiment analysis                             373  \n",
       "4.2 table-to-text generation                       424  \n",
       "4.3 questing answering                             387  \n",
       "4.3 questing answering                             514  \n",
       "4.3 questing answering                             511  \n",
       "5 analysis and ablation study                        7  \n",
       "5.1 number of in-context examples                  178  \n",
       "5.2 size of training set for retrieval             391  \n",
       "5.2 size of training set for retrieval             382  \n",
       "5.2 size of training set for retrieval               7  \n",
       "5.3 order of in-context examples                   394  \n",
       "6 related work                                     554  \n",
       "6 related work                                     503  \n",
       "6 related work                                       7  \n",
       "7 conclusion                                       644  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a token count column\n",
    "chapter_contents_long_df['num_tokens_oai'] = chapter_contents_long_df['contents_split'].apply(\n",
    "    lambda x: utl.num_tokens_from_messages([{'message': x}])\n",
    ")\n",
    "\n",
    "chapter_contents_long_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapter_contents_long_df['text'] = \"CHAPTER: \" +  chapter_contents_long_df.index + \" CONTENT: \" + chapter_contents_long_df['contents_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop contents_split column\n",
    "chapter_contents_long_df = chapter_contents_long_df.drop(columns=['contents_split'])\n",
    "# Reset index so chapter names are stored in columns\n",
    "chapter_contents_long_df = chapter_contents_long_df.reset_index()\n",
    "# Rename index column to chapter\n",
    "chapter_contents_long_df = chapter_contents_long_df.rename(columns={'index': 'chapter'})\n",
    "# Add session_name column\n",
    "chapter_contents_long_df['session_name'] = session_name\n",
    "## Add interaction type column\n",
    "chapter_contents_long_df['interaction_type'] = 'source'\n",
    "## Drop rows where num_tokens_oai is less than 100\n",
    "chapter_contents_long_df = chapter_contents_long_df[chapter_contents_long_df['num_tokens_oai'] > 50].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chapter</th>\n",
       "      <th>num_tokens_oai</th>\n",
       "      <th>text</th>\n",
       "      <th>session_name</th>\n",
       "      <th>interaction_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>338</td>\n",
       "      <td>CHAPTER: abstract CONTENT:  gpt-3 (brown et al...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 introduction</td>\n",
       "      <td>549</td>\n",
       "      <td>CHAPTER: 1 introduction CONTENT:  gpt-3 (brown...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 introduction</td>\n",
       "      <td>511</td>\n",
       "      <td>CHAPTER: 1 introduction CONTENT: he recent suc...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.1 gpt-3 for in-context learning</td>\n",
       "      <td>489</td>\n",
       "      <td>CHAPTER: 2.1 gpt-3 for in-context learning CON...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.2 the impact of in-context examples</td>\n",
       "      <td>377</td>\n",
       "      <td>CHAPTER: 2.2 the impact of in-context examples...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.3 knn-augmented in-context example</td>\n",
       "      <td>415</td>\n",
       "      <td>CHAPTER: 2.3 knn-augmented in-context example ...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.3 knn-augmented in-context example</td>\n",
       "      <td>425</td>\n",
       "      <td>CHAPTER: 2.3 knn-augmented in-context example ...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 experimental setup</td>\n",
       "      <td>246</td>\n",
       "      <td>CHAPTER: 3 experimental setup CONTENT:  we app...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.1 sentence embeddings for retrieval</td>\n",
       "      <td>440</td>\n",
       "      <td>CHAPTER: 3.1 sentence embeddings for retrieval...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.1 sentence embeddings for retrieval</td>\n",
       "      <td>436</td>\n",
       "      <td>CHAPTER: 3.1 sentence embeddings for retrieval...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.2 baseline methods</td>\n",
       "      <td>416</td>\n",
       "      <td>CHAPTER: 3.2 baseline methods CONTENT:  random...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.1 sentiment analysis</td>\n",
       "      <td>373</td>\n",
       "      <td>CHAPTER: 4.1 sentiment analysis CONTENT:  we ﬁ...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.2 table-to-text generation</td>\n",
       "      <td>424</td>\n",
       "      <td>CHAPTER: 4.2 table-to-text generation CONTENT:...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.3 questing answering</td>\n",
       "      <td>387</td>\n",
       "      <td>CHAPTER: 4.3 questing answering CONTENT:  we a...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.3 questing answering</td>\n",
       "      <td>514</td>\n",
       "      <td>CHAPTER: 4.3 questing answering CONTENT:  and ...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.3 questing answering</td>\n",
       "      <td>511</td>\n",
       "      <td>CHAPTER: 4.3 questing answering CONTENT: lege ...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1 number of in-context examples</td>\n",
       "      <td>178</td>\n",
       "      <td>CHAPTER: 5.1 number of in-context examples CON...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.2 size of training set for retrieval</td>\n",
       "      <td>391</td>\n",
       "      <td>CHAPTER: 5.2 size of training set for retrieva...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.2 size of training set for retrieval</td>\n",
       "      <td>382</td>\n",
       "      <td>CHAPTER: 5.2 size of training set for retrieva...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.3 order of in-context examples</td>\n",
       "      <td>394</td>\n",
       "      <td>CHAPTER: 5.3 order of in-context examples CONT...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6 related work</td>\n",
       "      <td>554</td>\n",
       "      <td>CHAPTER: 6 related work CONTENT:  pre-trained ...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6 related work</td>\n",
       "      <td>503</td>\n",
       "      <td>CHAPTER: 6 related work CONTENT:  al., 2018; w...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7 conclusion</td>\n",
       "      <td>644</td>\n",
       "      <td>CHAPTER: 7 conclusion CONTENT:  this work pres...</td>\n",
       "      <td>good_incontext_examples_for_gpt3</td>\n",
       "      <td>source</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   chapter  num_tokens_oai  \\\n",
       "0                                 abstract             338   \n",
       "1                           1 introduction             549   \n",
       "2                           1 introduction             511   \n",
       "4        2.1 gpt-3 for in-context learning             489   \n",
       "5    2.2 the impact of in-context examples             377   \n",
       "6     2.3 knn-augmented in-context example             415   \n",
       "7     2.3 knn-augmented in-context example             425   \n",
       "8                     3 experimental setup             246   \n",
       "9    3.1 sentence embeddings for retrieval             440   \n",
       "10   3.1 sentence embeddings for retrieval             436   \n",
       "11                    3.2 baseline methods             416   \n",
       "13                  4.1 sentiment analysis             373   \n",
       "14            4.2 table-to-text generation             424   \n",
       "15                  4.3 questing answering             387   \n",
       "16                  4.3 questing answering             514   \n",
       "17                  4.3 questing answering             511   \n",
       "19       5.1 number of in-context examples             178   \n",
       "20  5.2 size of training set for retrieval             391   \n",
       "21  5.2 size of training set for retrieval             382   \n",
       "23        5.3 order of in-context examples             394   \n",
       "24                          6 related work             554   \n",
       "25                          6 related work             503   \n",
       "27                            7 conclusion             644   \n",
       "\n",
       "                                                 text  \\\n",
       "0   CHAPTER: abstract CONTENT:  gpt-3 (brown et al...   \n",
       "1   CHAPTER: 1 introduction CONTENT:  gpt-3 (brown...   \n",
       "2   CHAPTER: 1 introduction CONTENT: he recent suc...   \n",
       "4   CHAPTER: 2.1 gpt-3 for in-context learning CON...   \n",
       "5   CHAPTER: 2.2 the impact of in-context examples...   \n",
       "6   CHAPTER: 2.3 knn-augmented in-context example ...   \n",
       "7   CHAPTER: 2.3 knn-augmented in-context example ...   \n",
       "8   CHAPTER: 3 experimental setup CONTENT:  we app...   \n",
       "9   CHAPTER: 3.1 sentence embeddings for retrieval...   \n",
       "10  CHAPTER: 3.1 sentence embeddings for retrieval...   \n",
       "11  CHAPTER: 3.2 baseline methods CONTENT:  random...   \n",
       "13  CHAPTER: 4.1 sentiment analysis CONTENT:  we ﬁ...   \n",
       "14  CHAPTER: 4.2 table-to-text generation CONTENT:...   \n",
       "15  CHAPTER: 4.3 questing answering CONTENT:  we a...   \n",
       "16  CHAPTER: 4.3 questing answering CONTENT:  and ...   \n",
       "17  CHAPTER: 4.3 questing answering CONTENT: lege ...   \n",
       "19  CHAPTER: 5.1 number of in-context examples CON...   \n",
       "20  CHAPTER: 5.2 size of training set for retrieva...   \n",
       "21  CHAPTER: 5.2 size of training set for retrieva...   \n",
       "23  CHAPTER: 5.3 order of in-context examples CONT...   \n",
       "24  CHAPTER: 6 related work CONTENT:  pre-trained ...   \n",
       "25  CHAPTER: 6 related work CONTENT:  al., 2018; w...   \n",
       "27  CHAPTER: 7 conclusion CONTENT:  this work pres...   \n",
       "\n",
       "                        session_name interaction_type  \n",
       "0   good_incontext_examples_for_gpt3           source  \n",
       "1   good_incontext_examples_for_gpt3           source  \n",
       "2   good_incontext_examples_for_gpt3           source  \n",
       "4   good_incontext_examples_for_gpt3           source  \n",
       "5   good_incontext_examples_for_gpt3           source  \n",
       "6   good_incontext_examples_for_gpt3           source  \n",
       "7   good_incontext_examples_for_gpt3           source  \n",
       "8   good_incontext_examples_for_gpt3           source  \n",
       "9   good_incontext_examples_for_gpt3           source  \n",
       "10  good_incontext_examples_for_gpt3           source  \n",
       "11  good_incontext_examples_for_gpt3           source  \n",
       "13  good_incontext_examples_for_gpt3           source  \n",
       "14  good_incontext_examples_for_gpt3           source  \n",
       "15  good_incontext_examples_for_gpt3           source  \n",
       "16  good_incontext_examples_for_gpt3           source  \n",
       "17  good_incontext_examples_for_gpt3           source  \n",
       "19  good_incontext_examples_for_gpt3           source  \n",
       "20  good_incontext_examples_for_gpt3           source  \n",
       "21  good_incontext_examples_for_gpt3           source  \n",
       "23  good_incontext_examples_for_gpt3           source  \n",
       "24  good_incontext_examples_for_gpt3           source  \n",
       "25  good_incontext_examples_for_gpt3           source  \n",
       "27  good_incontext_examples_for_gpt3           source  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter_contents_long_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get embeddings for each content piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_for_embed_df = chapter_contents_long_df[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0039588"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the cost of running the model to get embeddings\n",
    "(chapter_contents_long_df['num_tokens_oai'].sum() / 1000) * 0.0004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed each chapter\n",
    "rng = tqdm(range(0,len(contents_for_embed_df)))\n",
    "\n",
    "contents_embedded = {}\n",
    "\n",
    "for i in rng:\n",
    "    txt_chapter = contents_for_embed_df.index[i]\n",
    "    txt_list = contents_for_embed_df.iloc[i].to_list()\n",
    "\n",
    "    txt_embed = utl.get_embedding(txt_list)\n",
    "\n",
    "\n",
    "\n",
    "    # Join embeddings with context table\n",
    "    contents_embedded[txt_chapter] = txt_embed\n",
    "embeded_s = pd.Series(contents_embedded, index=contents_embedded.keys())\n",
    "\n",
    "# Merge embeddings with chapter contents\n",
    "chapter_contents_long_df['embedding'] = embeded_s\n",
    "chapter_contents_long_df.head()\n",
    "\n",
    "# Save embeddings\n",
    "chapter_contents_long_df.to_csv(f'./data/{session_name}_embeded.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find most similar document embeddings to the question embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read embeddings\n",
    "chapter_contents_long_df = pd.read_csv(prm.D_PTH  / f'{session_name}_embeded.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context table for session: \"good_incontext_examples_for_gpt3\" created\n"
     ]
    }
   ],
   "source": [
    "# DB INTERACTION\n",
    "# Insert context into DB\n",
    "conn = utl.create_connection(prm.DB_PTH)\n",
    "utl.insert_context(conn, session_name, chapter_contents_long_df)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interaction type: \"user\" inserted into the database for session: \"good_incontext_examples_for_gpt3\"\n",
      "Interaction type: \"assistant\" inserted into the database for session: \"good_incontext_examples_for_gpt3\"\n"
     ]
    }
   ],
   "source": [
    "# Buiild seed conversation context for summarization\n",
    "# TODO: no need to get embedding each time the script is run. Optimize it.\n",
    "\n",
    "summary_ctx_usr = \"How would you act when I'd ask you what this document is about. Can you summarize it for me?\"\n",
    "\n",
    "summary_ctxt_asst = \"When a user asks me to summarize the source material or explain what it is about, I would look for the best text fragment that provides general information about the document's contents. To find a text fragment for summarization, I suggest starting by scanning the abstract and conclusion sections, and also checking the table of contents.\"\n",
    "\n",
    "utl.bulk_insert_interaction(conn, summary_ctx_usr, summary_ctxt_asst, session_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will answer your question basing on the following context: {'3.1 sentence embeddings for retrieval', '3.2 baseline methods', '2.1 gpt-3 for in-context learning', 'abstract', '1 introduction'}\n",
      "Number of tokens passed to the model: 2618\n",
      "Number of tokens left in the context: 1478\n",
      "Interaction type: \"user\" inserted into the database for session: \"good_incontext_examples_for_gpt3\"\n",
      "Interaction type: \"assistant\" inserted into the database for session: \"good_incontext_examples_for_gpt3\"\n",
      "'USER:'\n",
      "'tell me what zero shot learning is? '\n",
      "'---------------------------------'\n",
      "'ASSISTANT:'\n",
      "('I apologize, but the information you are requesting is not directly related '\n",
      " 'to the context of the sources provided. However, zero-shot learning refers '\n",
      " 'to the ability of a machine learning model to perform a task without any '\n",
      " 'training examples specifically for that task. Instead, the model uses its '\n",
      " 'prior knowledge to complete the task based on a few examples or a general '\n",
      " 'understanding of the problem. For example, a language model that can '\n",
      " 'translate between languages it has not been trained on would be an example '\n",
      " 'of zero-shot learning.')\n",
      "'---------------------------------'\n",
      "'CONTEXT:'\n",
      "('SOURCE: CHAPTER: 1 introduction CONTENT: he recent success of '\n",
      " 'retrieval-augmented models (hashimoto et al., 2018), we propose to utilize '\n",
      " 'nearest neighbors of a given test sample (among all the training instances '\n",
      " 'available) as the corresponding in-context exam- ples. the retrieved '\n",
      " 'examples, along with the test sample, are provided to gpt-3 for the ﬁnal '\n",
      " 'predic- tion. to verify the effectiveness of the proposed method, we '\n",
      " 'evaluate it on several natural language understanding and generation tasks, '\n",
      " 'including sen- timent analysis, table-to-text generation and open- domain '\n",
      " 'question answering. it is observed that the retrieval-based in-context '\n",
      " 'examples unleash the few-shot capabilities of gpt-3 much more ef- fectively '\n",
      " 'than a random sampling baseline. even with a smaller number of in-context '\n",
      " 'examples, the proposed strategy empowers gpt-3 to achieve stronger '\n",
      " 'performance. moreover, we ﬁnd that the speciﬁc sentence encoders employed '\n",
      " 'for the re- trieval procedure play a critical role. thus, an ex- tensive '\n",
      " 'exploration regarding different pre-trained encoders is conducted, and it is '\n",
      " 'shown that en- coders ﬁne-tuned on natural language matching tasks serve as '\n",
      " 'more effective in-context examples selector on the qa task. detailed '\n",
      " 'analysis and case study further validate the effectiveness of pro- posed '\n",
      " 'methods. in summary, our contributions in this paper are as follows: i) to '\n",
      " 'the best of our knowledge, we take a ﬁrst step towards understanding the '\n",
      " 'sensitivity of gpt- 3’s few-shot capabilities with respect to the selec- '\n",
      " 'tion of in-context examples; ii) to alleviate the sensitivity issue, an ad- '\n",
      " 'ditional retrieval module is introduced to ﬁnd semantically-similar '\n",
      " 'in-context examples of a test instance to construct its corresponding input, '\n",
      " 'which greatly outperforms the baseline based on random sampled examples; '\n",
      " 'iii) ﬁne-tuning the retrieval model on task- related dataset(s) leads to '\n",
      " 'even stronger empirical results with gpt-3; iv) the performance of gpt-3 '\n",
      " 'improves as the number of examples available for retrieval in- creases. '\n",
      " 'figure 1: the ﬁgure above shows how to perform in- context learning with a '\n",
      " 'language model. three in- context examples and the test prompt are '\n",
      " 'concatenated as a single string input for gpt-3, with a special charac- ter '\n",
      " '”\\\\n” inserted between two adjacent examples. gpt- 3 keeps generating tokens '\n",
      " 'until there is a special char- acter ”\\\\n”. | CHAPTER: 3.2 baseline methods '\n",
      " 'CONTENT:  random sampling for each test sentence, we randomly select '\n",
      " 'in-context examples from the training set. we refer to this method as random '\n",
      " 'in the experimental results. to have a fair compar- ison with kate, the '\n",
      " 'number of in-context exam- ples in this random baseline is the same as kate '\n",
      " '2the totto code base can be found at https: '\n",
      " '//github.com/google-research/language/ tree/master/language/totto method '\n",
      " 'random knnroberta kateroberta katenli katenli+sts-b katesst-2 accuracy 87.95 '\n",
      " '± 2.74 50.20 91.99 90.40 90.20 93.43 table 4: accuracy of sentiment '\n",
      " 'prediction for gpt-3 on imdb with different choices of in-context exam- '\n",
      " 'ples. in-context examples are from the sst-2 dataset. to ensure fair '\n",
      " 'comparison. on the test set, the ran- dom baseline is repeated for ﬁve times '\n",
      " 'to obtain the average score and corresponding standard de- viation. '\n",
      " 'k-nearest neighbor additionally, to investi- gate whether the retrieval '\n",
      " 'module is complemen- tary to gpt-3’s few-shot learning ability, we further '\n",
      " 'consider a k-nearest neighbor baseline. speciﬁcally, for text generation '\n",
      " 'tasks, the target y1 associated with the ﬁrst retrieved example is '\n",
      " 'considered as the predicted target for the test sam- ple. as to the '\n",
      " 'sentiment analysis and qa tasks, the top k retrieved examples {y1, ..., yk} '\n",
      " 'are utilized, where the ﬁnal prediction is determined by major- ity voting '\n",
      " 'among the k examples’ targets. if there is a tie case, we take the target of '\n",
      " 'the example that is most similar to the test sentence as the predic- tion. '\n",
      " 'to ensure fair comparison, we compare the baseline knn and kate under the '\n",
      " 'same embed- ding space of a pre-trained roberta-large model. this baseline '\n",
      " 'is abbreviated as knnroberta. | CHAPTER: abstract CONTENT:  gpt-3 (brown et '\n",
      " 'al., 2020) has attracted lots of attention due to its superior performance '\n",
      " 'across a wide range of nlp tasks, especially with its powerful and versatile '\n",
      " 'in-context few- shot learning ability. despite its success, we found that '\n",
      " 'the empirical results of gpt-3 de- pend heavily on the choice of in-context '\n",
      " 'ex- amples. in this work, we investigate whether there are more effective '\n",
      " 'strategies for judi- ciously selecting in-context examples (relative to '\n",
      " 'random sampling) that better leverage gpt- 3’s few-shot capabilities. '\n",
      " 'inspired by the re- cent success of leveraging a retrieval module to augment '\n",
      " 'large-scale neural network mod- els, we propose to retrieve examples that '\n",
      " 'are semantically-similar to a test sample to for- mulate its corresponding '\n",
      " 'prompt. intuitively, the in-context examples selected with such a strategy '\n",
      " 'may serve as more informative in- puts to unleash gpt-3’s extensive '\n",
      " 'knowledge. we evaluate the proposed approach on sev- eral natural language '\n",
      " 'understanding and gen- eration benchmarks, where the retrieval-based prompt '\n",
      " 'selection approach consistently out- performs the random baseline. moreover, '\n",
      " 'it is observed that the sentence encoders ﬁne- tuned on task-related '\n",
      " 'datasets yield even more helpful retrieval results. notably, signiﬁcant '\n",
      " 'gains are observed on tasks such as table-to- text generation (41.9% on the '\n",
      " 'totto dataset) and open-domain question answering (45.5% on the nq dataset). '\n",
      " 'we hope our investigation could help understand the behaviors of gpt-3 and '\n",
      " 'large-scale pre-trained lms in general and enhance their few-shot '\n",
      " 'capabilities. | CHAPTER: 2.1 gpt-3 for in-context learning CONTENT:  the '\n",
      " 'in-context learning scenario of gpt-3 can be regarded as a conditional text '\n",
      " 'generation problem. concretely, the probability of generating a target y is '\n",
      " 'conditioned on the context c, which includes k examples, and the source x. '\n",
      " 'therefore, the pre- diction y corresponding to the source x can be ex- '\n",
      " 'pressed as: plm(y|c, x) = t (cid:89) t=1 p(yt|c, x, y<t) (1) where lm '\n",
      " 'denotes the parameters of the language model, and c = {x1, y1, x2, y2, ..., '\n",
      " 'xk, yk} is a context string. in gpt-3, the c is created by con- catenating k '\n",
      " 'training instances along with their corresponding labels. as shown in the '\n",
      " 'illustration of figure 1, gpt-3 is asked to translate “moun- tain” to its '\n",
      " 'german version based on the three ex- amples given as part of the input. for '\n",
      " 'gpt-3, this generation process is imple- mented through a giant '\n",
      " 'transformer-based model architecture (vaswani et al., 2017; brown et al., '\n",
      " '2020). given the large size of the gpt-3 model, it would be very '\n",
      " 'computationally-involved to ﬁne- tune it on task-speciﬁc samples. thus, '\n",
      " 'gpt-3 is typically leveraged in a in-context learning man- ner as described '\n",
      " 'above. it has been shown that gpt-3 has powerful few-shot capabilities, '\n",
      " 'where it can perform quite well with only a small num- ber of demonstrations '\n",
      " 'provided. unfortunately, as shown in table 1, the results of gpt tends to '\n",
      " 'ﬂuc- tuate signiﬁcantly with different in-context exam- ples chosen. here we '\n",
      " 'aim to alleviate this issue via judious in-context examples selection. '\n",
      " '1234sourcetargetcontextpromptwatermelon == wassermelonesports car == '\n",
      " 'sportwagenblue sky == blauer himmelmountain == ……………. figure 2: in-context '\n",
      " 'example selection for gpt-3. white dots: unused training samples; grey dots: '\n",
      " 'randomly sam- pled training samples; red dots: training samples selected by '\n",
      " 'the k-nearest neighbors algorithm in the embedding space of a sentence '\n",
      " 'encoder. | CHAPTER: 3.1 sentence embeddings for retrieval CONTENT: table and '\n",
      " 'a set of highlighted cells, this task fo- cuses on producing human-readable '\n",
      " 'texts as de- scriptions. totto (parikh et al., 2020) is uti- lized for '\n",
      " 'evaluation due to its popularity. we use bleu (papineni et al., 2002) and '\n",
      " 'parent (dhin- gra et al., 2019). metrics for evaluation. the totto code base '\n",
      " 'contains both evaluation and preprocessing scripts2. due to the input length '\n",
      " 'limit of gpt-3 (currently the token limit is 2048), we add an extra '\n",
      " 'preprocessing step by deleting the closing angle brackets such as </cell> '\n",
      " 'and </table> to save some space. the number of in- context examples is set '\n",
      " 'as 2 . question answering given a factual question, the model is asked to '\n",
      " 'generate the correct answer. following prior studies, we use the exact match '\n",
      " '(em) score to measure the performance of gpt- 3 on open-domain qa tasks. the '\n",
      " 'em score is deﬁned as the proportion of the number of pre- dicted answers '\n",
      " 'being exactly the same as (one of) the ground-truth answer(s). the matching '\n",
      " 'is per- formed after string normalization, which includes article and '\n",
      " 'punctuation removal. we conduct experiments on three open-domain qa bench- '\n",
      " 'marks: natural questions (nq) (kwiatkowski et al., 2019), web questions (wq) '\n",
      " '(berant et al., 2013), and trivia question answering (trivi- aqa) (joshi et '\n",
      " 'al., 2017). for this task, we pick the nearest 64 neighbors as the '\n",
      " 'in-context exam- ples for nq and wq and nearest 10 neighbors for triviaqa '\n",
      " '(the retrieved 64 examples could not ﬁt into 2048 token limit for triviaqa. '\n",
      " 'for fair com- parison, we set the number of in-context examples to be 10 for '\n",
      " 'triviaqa for both the baseline and kate method). the evaluation is done on '\n",
      " 'the test sets of nq and wq and the dev set of triviaqa. ')\n",
      "'USER: are there any comparisons to other language models?'\n",
      "('ASSISTANT: SRC: CHAPTER 1 introduction\\n'\n",
      " 'CONTENT: The authors of the paper chose GPT-3 as the subject of their '\n",
      " 'research due to its impressive in-context few-shot learning ability, '\n",
      " 'allowing it to generalize to unseen cases without further fine-tuning. This '\n",
      " 'ability opens up new technological possibilities such as developing NLP '\n",
      " 'systems to expand emails, extract entities from text, or generate code based '\n",
      " 'on natural language instructions with only a few demonstration examples. \\n'\n",
      " '\\n'\n",
      " 'The authors note that while GPT-3 has powerful in-context learning '\n",
      " 'abilities, it does have practical challenges/ambiguities. The performance of '\n",
      " 'GPT-3 tends to fluctuate with different choices of in-context examples. '\n",
      " 'Therefore, the authors aimed to examine how to better select in-context '\n",
      " 'examples to unleash GPT-3s few-shot learning capabilities and improve its '\n",
      " 'performance.')\n"
     ]
    }
   ],
   "source": [
    "# POC - conversational interface\n",
    "\n",
    "## Define how many samples you want to get from the recall table\n",
    "num_samples = 5\n",
    "## Get unix time\n",
    "query_time = int(datetime.now().timestamp())\n",
    "## User input\n",
    "question = input(\">>> \")\n",
    "# question = prmt\n",
    "\n",
    "\n",
    "## Fetch recal table so we can compare user input to embeddings saved in it and fetch the right context.\n",
    "recal_table = utl.fetch_recall_table(session_name)\n",
    "\n",
    "## Chop recall table to only include contexts for sources, user, or assistant\n",
    "recal_table_source = recal_table[recal_table['interaction_type'] == 'source']\n",
    "recal_table_user = recal_table[recal_table['interaction_type'] == 'user']\n",
    "recal_table_assistant = recal_table[recal_table['interaction_type'] == 'assistant']\n",
    "\n",
    "recal_embed_source = utl.convert_table_to_dct(recal_table_source)\n",
    "recal_embed_user = utl.convert_table_to_dct(recal_table_user)\n",
    "recal_embed_assistant = utl.convert_table_to_dct(recal_table_assistant)\n",
    "\n",
    "## Get the context from recal table that is the most similar to user input\n",
    "if recal_table_source.shape[0]<num_samples:\n",
    "    num_samples = recal_table_source.shape[0]\n",
    "    print('Source material is shorter than number of samples you want to get. Setting number of samples to the number of source material sections.')\n",
    "\n",
    "## Get SRC context\n",
    "if len(recal_embed_source) == 0:\n",
    "    recal_source = 'No context found'\n",
    "else:\n",
    "    recal_source_id = utl.order_document_sections_by_query_similarity(question, recal_embed_source)[0:num_samples]\n",
    "    # If recal source id is a list, join the text from the list\n",
    "    if len(recal_source_id)>1:\n",
    "        idxs = [x[1] for x in recal_source_id]\n",
    "        recal_source = recal_table.loc[idxs]['text'].to_list()\n",
    "        recal_source = '| '.join(recal_source)\n",
    "    else: \n",
    "        recal_source = recal_table.loc[recal_source_id[1]]['text']\n",
    "## GET QRY context\n",
    "if len(recal_embed_user) == 0:\n",
    "    recal_user = 'No context found'\n",
    "else:\n",
    "    recal_user_id = utl.order_document_sections_by_query_similarity(question, recal_embed_user)[0][1]\n",
    "    recal_user = recal_table.loc[recal_user_id]['text']\n",
    "## GET RPL context\n",
    "if len(recal_embed_assistant) == 0:\n",
    "    recal_assistant = 'No context found'\n",
    "else:\n",
    "    recal_assistant_id = utl.order_document_sections_by_query_similarity(question, recal_embed_assistant)[0][1]\n",
    "    recal_assistant = recal_table.loc[recal_assistant_id]['text']\n",
    "\n",
    "\n",
    "# Look for assistant and user messages in the interaction table that have the latest time_signature\n",
    "last_usr_max = recal_table_user['time_signature'].astype(int).max()\n",
    "last_asst_max = recal_table_assistant['time_signature'].astype(int).max()\n",
    "if last_usr_max == 0:\n",
    "    latest_user = 'No context found'\n",
    "else:\n",
    "    latest_user = recal_table_user.loc[recal_table_user['time_signature']==str(last_usr_max)]['text'].values[0]\n",
    "\n",
    "if last_asst_max == 0:\n",
    "    latest_assistant = 'No context found'\n",
    "else:\n",
    "    latest_assistant = recal_table_assistant.loc[recal_table_assistant['time_signature']==str(last_asst_max)]['text'].values[0]\n",
    "\n",
    "\n",
    "## Grab chapter name if it exists, otherwise use session name\n",
    "## It will become handy when user wants to know from which chapter the context was taken\n",
    "if len(recal_source_id)>1:\n",
    "    recal_source_chapter = recal_table.loc[idxs]['chapter'].to_list()\n",
    "else:\n",
    "    recal_source_chapter = recal_table.loc[recal_source_id[1]]['chapter']\n",
    "\n",
    "print(f'I will answer your question basing on the following context: {set(recal_source_chapter)}')\n",
    "\n",
    "###############################################################################\n",
    "# Set-up system prompts. This is done once for the whole session and the setup depends on the type of assistant chosen by the user.\n",
    "# I comnment this out as this needs to be saved in the interaction table and I will implement this after user-assistant interactions are implemented.\n",
    "\n",
    "sys_message = {\n",
    "        'role': 'system', \n",
    "        'content': \"You are a helpful assistant. You provide only factual information. If you do not know the answer, you say it. I provide my input after INP tag. I will pass the context you will use in your answer. I encode it with following tags: SRC - sources we are talking about; QRY - one of previous inputs I passed to you in the conversation; RPL - one of your previous replies to my questions from the conversation.\"\n",
    "        }\n",
    "prev_user = {\"role\": \"user\", \"content\": f\"{latest_user}\"}\n",
    "prev_assistant = {\"role\": \"assistant\", \"content\": f\"{latest_assistant}\"}\n",
    "user_message = {\n",
    "        \"role\": \"user\", \n",
    "        \"content\": f\"SRC: {recal_source}. QRY: {recal_user}. RPL: {recal_assistant}. INP: {question}\"\n",
    "        }\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "## Form user message based on recaled context and user's input\n",
    "usr_message = [\n",
    "    sys_message,\n",
    "    prev_user,\n",
    "    prev_assistant,\n",
    "    user_message\n",
    "    ]\n",
    "\n",
    "# Count number of tokens in user message and display it to the user\n",
    "token_passed = utl.num_tokens_from_messages(usr_message)\n",
    "context_capacity =  4096 - token_passed\n",
    "print(f\"Number of tokens passed to the model: {token_passed}\")\n",
    "print(f\"Number of tokens left in the context: {context_capacity}\")\n",
    "\n",
    "# Grab call user content from messages alias\n",
    "usr_message_content = usr_message[0]['content']\n",
    "\n",
    "\n",
    "## Make API call with formed user message\n",
    "api_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=usr_message\n",
    ")\n",
    "\n",
    "\n",
    "# Open DB so the assistant can remember the conversation\n",
    "conn = utl.create_connection(prm.DB_PTH)\n",
    "# Insert user message into DB so we can use it for another user's input\n",
    "utl.insert_interaction(\n",
    "    conn, \n",
    "    session_name, \n",
    "    'user', \n",
    "    question,\n",
    "    query_time\n",
    "    )\n",
    "# Insert model's response into DB so we can use it for another user's input\n",
    "utl.insert_interaction(\n",
    "    conn,\n",
    "    session_name,\n",
    "    'assistant',\n",
    "    api_response['choices'][0]['message']['content'],\n",
    "    api_response['created']\n",
    "    )\n",
    "conn.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Print CALL and RESPONSE\n",
    "pprint.pprint('USER:')\n",
    "pprint.pprint(question)\n",
    "pprint.pprint('---------------------------------')\n",
    "pprint.pprint('ASSISTANT:')\n",
    "pprint.pprint(api_response['choices'][0]['message']['content'])\n",
    "## Print additional context data:\n",
    "pprint.pprint('---------------------------------')\n",
    "pprint.pprint('CONTEXT:')\n",
    "pprint.pprint(f\"SOURCE: {recal_source}\")\n",
    "pprint.pprint(f\"USER: {recal_user}\")\n",
    "pprint.pprint(f\"ASSISTANT: {recal_assistant}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3289b5bb5c2761f56c4426244bcf49eab0c0b4a9e2bf0f472f2bef28cce96346"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
